{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOUOExGwAh0YvSwtMV7sWPG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ebamberg/research-projects-ml/blob/main/Evaluation/examples_evaluation_LLM_Outputs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# # Evaluating LLM Output\n",
        "\n",
        "F1-Score (Precision/Recall)\n",
        "ROUGE\n",
        "BLEU\n",
        "\n",
        "Use BLEU when evaluating machine translation tasks, where precision and fluency are critical.\n",
        "Use ROUGE for summarization tasks where capturing key ideas and recall is more important than exact wording.\n",
        "\n",
        "AUC-ROC- distinguised between classes\n",
        "\n",
        "|LLM task        | evaluation metric | frameworks|\n",
        "|----------------|-------------------|-----------|\n",
        "| Classification | F1-Score, AUC-ROC |           |\n",
        "| Regression     | Mean Squared Error (MSE),Root Mean Squared Error (RMSE),Mean Absolute Error (MAE),R-squared (R²)                  |           |\n",
        "| Summarization  | ROUGE             | rouge-score, evaluate      |\n",
        "| Translation    | BLEU              | nltk, evaluate, sacrebleu |\n"
      ],
      "metadata": {
        "id": "FqKtTGCXw-CY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ewl8CHOQw9SL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d859e0e1-40d0-4909-9cae-436ddb1a84d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.5.0-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.26.4)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.17.0)\n",
            "Collecting datasets>=2.0.0 (from evaluate)\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting dill (from evaluate)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Collecting xxhash (from evaluate)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from evaluate)\n",
            "  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.10.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.27.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\n",
            "Collecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (5.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Collecting dill (from evaluate)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk rouge-score evaluate sacrebleu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing evaluate library\n",
        "import evaluate\n",
        "\n",
        "# Load the BLEU and ROUGE metrics\n",
        "bleu_metric = evaluate.load(\"bleu\")\n",
        "rouge_metric = evaluate.load(\"rouge\")\n",
        "\n",
        "# Example sentences (non-tokenized)\n",
        "reference = [\"the cat is on the mat\"]\n",
        "candidate = [\"the cat is on mat\"]\n",
        "\n",
        "# BLEU expects plain text inputs\n",
        "bleu_results = bleu_metric.compute(predictions=candidate, references=reference)\n",
        "print(f\"BLEU Score: {bleu_results['bleu'] * 100:.2f}\")\n",
        "\n",
        "# ROUGE expects plain text inputs\n",
        "rouge_results = rouge_metric.compute(predictions=candidate, references=reference)\n",
        "\n",
        "# Access ROUGE scores (no need for indexing into the result)\n",
        "print(f\"ROUGE-1 F1 Score: {rouge_results['rouge1']:.2f}\")\n",
        "print(f\"ROUGE-L F1 Score: {rouge_results['rougeL']:.2f}\")"
      ],
      "metadata": {
        "id": "Wr7Y9SEb1WYb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}