{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBaZIuYKx/klmzaGKjKgqY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ebamberg/research-projects-ml/blob/main/Document_Management/examples_build_knowledge_graph_with_instructor_framework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnTbWVjq5_B9",
        "outputId": "ba9b73da-76e0-48ed-c558-fcfb55f49b9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install ollama langchain_community  --quiet\n",
        "\n",
        "modelid=\"llama3.1\"\n",
        "emb_modelid=\"mxbai-embed-large\"\n",
        "host=\"localhost:11434\"\n",
        "\n",
        "get_ipython().system_raw(\"curl -fsSL https://ollama.com/install.sh | sh\")\n",
        "get_ipython().system_raw(\"ollama serve &\")\n",
        "get_ipython().system_raw(f\"ollama pull {modelid}\")\n",
        "get_ipython().system_raw(f\"ollama pull {emb_modelid}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install instructor --quiet"
      ],
      "metadata": {
        "id": "StvXnLGC6La3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydantic import BaseModel, Field\n",
        "from typing import Optional\n",
        "from graphviz import Digraph\n",
        "from IPython.display import display\n",
        "\n",
        "class Node(BaseModel):\n",
        "    id: int\n",
        "    label: str\n",
        "    color: str\n",
        "\n",
        "class Edge(BaseModel):\n",
        "    source: int\n",
        "    target: int\n",
        "    label: str\n",
        "    color: str = \"black\"\n",
        "\n",
        "\n",
        "class KnowledgeGraph(BaseModel):\n",
        "    nodes: list[Node] = Field(..., default_factory=list)  # A list of nodes in the knowledge graph.\n",
        "    edges: list[Edge] = Field(..., default_factory=list)  # A list of edges in the knowledge graph.\n",
        "\n",
        "\n",
        "    def visualize_knowledge_graph(self):\n",
        "        dot = Digraph(comment=\"Knowledge Graph\")\n",
        "\n",
        "        for node in self.nodes:\n",
        "            dot.node(name=str(node.id), label=node.label, color=node.color)\n",
        "        for edge in self.edges:\n",
        "            dot.edge(str(edge.source), str(edge.target), label=edge.label, color=edge.color)\n",
        "\n",
        "        return display(dot)"
      ],
      "metadata": {
        "id": "U_WS8u_x6WCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_graph(input) -> KnowledgeGraph:\n",
        "    return client.chat.completions.create(\n",
        "        model=modelid,\n",
        "        messages=[\n",
        "            {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": f\"Help me understand the following by describing it as small knowledge graph: {input}\",\n",
        "            }\n",
        "        ],\n",
        "        response_model=KnowledgeGraph,\n",
        "    )\n",
        "\n",
        "generate_graph(\"Explain quantum mechanics\").visualize_knowledge_graph()\n"
      ],
      "metadata": {
        "id": "OCUzUYm87CG9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}