{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "name": "Document_Management/examples_document_person_statement_changed.ipynb",
      "authorship_tag": "ABX9TyPyz+ssgrkm/NtC+5C81V7k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ebamberg/research-projects-ml/blob/main/Document_Management/examples_document_person_statement_changed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ittnx9TnwT_y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GCm0uJVC9jvj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93b58b9c-d416-4d7d-fbc7-7370db88ced3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m114.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install ollama langchain_community --quiet\n",
        "\n",
        "host=\"localhost:11434\"\n",
        "modelid=\"llama3.2\"\n",
        "emb_modelid=\"mxbai-embed-large\"\n",
        "\n",
        "get_ipython().system_raw(\"curl -fsSL https://ollama.com/install.sh | sh\")\n",
        "get_ipython().system_raw(\"ollama serve &\")\n",
        "get_ipython().system_raw(f\"ollama pull {modelid}\")\n",
        "get_ipython().system_raw(f\"ollama pull {emb_modelid}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw(f\"ollama pull {modelid}\")"
      ],
      "metadata": {
        "id": "qOCItxi4HuqK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install atomic-agents instructor --quiet"
      ],
      "metadata": {
        "id": "8jw4YUzhqFIY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f6624ba-02fc-42e0-df52-8bf42de2bc63"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/79.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.2/79.2 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/656.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m656.0/656.0 kB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import instructor\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "from atomic_agents.agents.base_agent import BaseAgent, BaseAgentConfig, BaseIOSchema\n",
        "from atomic_agents.lib.components.agent_memory import AgentMemory\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "llm = OpenAI(\n",
        "        base_url=f\"http://{host}/v1\",\n",
        "        api_key=\"ollama\",  # required, but unused\n",
        "    )\n",
        "\n",
        "client = instructor.from_openai(\n",
        "    llm,\n",
        "    mode=instructor.Mode.JSON,\n",
        ")\n"
      ],
      "metadata": {
        "id": "yHCElQFQb2XR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from atomic_agents.lib.components.system_prompt_generator import SystemPromptGenerator\n",
        "from atomic_agents.agents.base_agent import BaseAgent, BaseAgentConfig, BaseIOSchema\n",
        "from atomic_agents.lib.components.agent_memory import AgentMemory\n",
        "from pydantic import Field\n",
        "from typing import Optional, List\n",
        "import instructor\n",
        "from instructor.client import Instructor\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\"Analyze the document and identify if the statements made by the person about [specific topic] change or remain consistent throughout the document. Provide examples of any changes or consistencies found.\"\n",
        "\"\"\"\n",
        "\n",
        "##################\n",
        "# Input Schema ###\n",
        "##################\n",
        "class DocumentStatementChangedValidatorInputSchema(BaseIOSchema):\n",
        "    \"\"\"\n",
        "    Defines a list of rules and a document.\n",
        "    \"\"\"\n",
        "    document: str = Field(...,description=\"The document to get analysed.\")\n",
        "    topic: str = Field(...,description=\"The specific topic we are analsing.\")\n",
        "\n",
        "################\n",
        "# Output SCHEMA #\n",
        "################\n",
        "class DocumentStatementChangedValidatorOutputSchema(BaseIOSchema):\n",
        "    \"\"\"\n",
        "    Schema for Output\n",
        "    \"\"\"\n",
        "    consistent: bool = Field (..., description=\"Is the statement in the document is consistent or not\")\n",
        "    changes: list[str] = Field (..., description=\"A list of changes\")\n",
        "    linenumbers: list[int] = Field (..., decription=\"line numbers where changes of statement occur \")\n",
        "\n",
        "###################\n",
        "# Build the agent #\n",
        "###################\n",
        "\n",
        "def build_document_statement_changed_validator_agent(client : Instructor, modelid: str) -> BaseAgent:\n",
        "    \"\"\"\n",
        "        builds an agent the validates if a statement has changed over time.\n",
        "\n",
        "    \"\"\"\n",
        "    return BaseAgent(\n",
        "        config=BaseAgentConfig(\n",
        "            client=client,\n",
        "            system_prompt_generator=SystemPromptGenerator(\n",
        "                background=[\n",
        "                'You are an expert in legal documents',\n",
        "                'Your task is to analyse a document'\n",
        "                ],\n",
        "                steps=[\n",
        "                    \"Add line numbers to the document.\"\n",
        "                    \"Analyze the document and identify if the statements made by the person about [specific topic] change or remain consistent throughout the document.\",\n",
        "                    \"Provide examples of any changes or consistencies found.\"\n",
        "                ],\n",
        "                output_instructions=[\n",
        "                    \"Ensure to output examples of any changes\",\n",
        "                    \"Ensure to add the linenumber where the changes occure.\"\n",
        "                ]\n",
        "            ),\n",
        "            input_schema=DocumentStatementChangedValidatorInputSchema,\n",
        "            output_schema=DocumentStatementChangedValidatorOutputSchema,\n",
        "            model=modelid,\n",
        "            temperature=0,\n",
        "        )\n",
        "    )\n"
      ],
      "metadata": {
        "id": "IoMJcVuvrJfG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document=\"\"\"\n",
        "Officer Reynolds: Good afternoon, Mrs. Harper. Thank you for coming in today. I'm Officer Reynolds, and we need to ask you some questions about your husband's death.\n",
        "\n",
        "Mrs. Harper: Good afternoon, Officer. I'll do my best to help, but I still can't believe what's happened.\n",
        "\n",
        "Officer Reynolds: I understand. We're just trying to piece together the events of that evening. Can you tell us where you were on the night of the murder?\n",
        "\n",
        "Mrs. Harper: Yes, I wasn't home that evening. I had a dinner with some friends in town.\n",
        "\n",
        "Officer Reynolds: You weren’t home at all that night?\n",
        "\n",
        "Mrs. Harper: No, I came back late, and by the time I got home, it was well past midnight. I found...I found him...\n",
        "\n",
        "Officer Reynolds: Do you have anyone who can confirm your whereabouts that evening?\n",
        "\n",
        "Mrs. Harper: Yes, I can provide you with the names of the friends I was with. They can vouch for me.\n",
        "\n",
        "Officer Reynolds: That would be helpful, Mrs. Harper. Now, if you don’t mind, can you walk me through what happened when you arrived back home?\n",
        "\n",
        "Mrs. Harper: Of course... When I got back, everything seemed normal at first. Then, I...I saw him lying there...\n",
        "\n",
        "Officer Reynolds: Take your time. It's important that we get a clear picture of that night.\n",
        "\n",
        "Mrs. Harper: I understand. I was in shock. I didn't know what to do.\n",
        "\n",
        "Officer Reynolds: Mrs. Harper, our investigation has led us to believe that you were actually at home during the time of the murder. Are you sure you weren’t there?\n",
        "\n",
        "Mrs. Harper: Wait, what? No, I told you, I wasn't home.\n",
        "\n",
        "Officer Reynolds: We have evidence suggesting otherwise. This is your last chance to be honest with us. Were you at home?\n",
        "\n",
        "Mrs. Harper: (sighs) Okay, okay... I... I was home. But I swear, I was asleep when it happened. I didn't do anything to him!\n",
        "\n",
        "Officer Reynolds: Thank you for your honesty, Mrs. Harper. We appreciate your cooperation. Can you tell us more about why you initially lied?\n",
        "\n",
        "Mrs. Harper: I was scared. I didn't want to be blamed for something I didn't do. I thought if I said I wasn’t there, it would be easier. I didn’t know what else to do.\n",
        "\n",
        "Officer Reynolds: We understand that this is difficult, but telling the truth is always the best course of action. Is there anything else you can share that might help our investigation?\n",
        "\n",
        "Mrs. Harper: I...I don't know. I just want to find out who did this to him. Please, believe me, I had nothing to do with it.\n",
        "\n",
        "Officer Reynolds: We will continue our investigation, Mrs. Harper. Thank you for your time. We'll be in touch.\n",
        "\n",
        "Mrs. Harper: Thank you, Officer. I hope you find the real culprit soon.\n",
        "\n",
        "Officer Reynolds: We'll do our best, Mrs. Harper. Take care.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "_kQHZldXFFYR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent=build_document_statement_changed_validator_agent(client, modelid)\n",
        "\n",
        "input=agent.input_schema(document=document, topic=\"location at time of murder\")\n",
        "validationResult=agent.run(input)\n",
        "validationResult"
      ],
      "metadata": {
        "id": "YkaTeOcP3HHu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7aba14aa-d122-4bcd-ea2f-a0e0900645fa"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DocumentStatementChangedValidatorOutputSchema(consistent=False, changes=[\"Initially said she wasn't home that evening but later admitted she was\", 'Changed her story about being asleep when the murder happened'], linenumbers=[10, 24])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}