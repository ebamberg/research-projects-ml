{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "name": "Document_Management/examples_document_person_statement_changed.ipynb",
      "authorship_tag": "ABX9TyOww1uprAtH5SgqVUph5guF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ebamberg/research-projects-ml/blob/main/Document_Management/examples_document_person_statement_changed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ittnx9TnwT_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ased upon: https://github.com/BrainBlend-AI/atomic-agents/blob/main/atomic-examples/web-search-agent/web_search_agent/tools/searxng_search.py"
      ],
      "metadata": {
        "id": "-MkARk87wUNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCm0uJVC9jvj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "674478a8-c131-440d-e1ca-9852bd2eade3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m119.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install ollama langchain_community --quiet\n",
        "\n",
        "host=\"localhost:11434\"\n",
        "modelid=\"llama3.2\"\n",
        "emb_modelid=\"mxbai-embed-large\"\n",
        "\n",
        "get_ipython().system_raw(\"curl -fsSL https://ollama.com/install.sh | sh\")\n",
        "get_ipython().system_raw(\"ollama serve &\")\n",
        "get_ipython().system_raw(f\"ollama pull {modelid}\")\n",
        "get_ipython().system_raw(f\"ollama pull {emb_modelid}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install atomic-agents instructor --quiet"
      ],
      "metadata": {
        "id": "8jw4YUzhqFIY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c72b25c-28b2-41de-a56f-738495b74878"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/71.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/656.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m656.0/656.0 kB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting googlesearch_python\n",
            "  Downloading googlesearch_python-1.3.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: beautifulsoup4>=4.9 in /usr/local/lib/python3.11/dist-packages (from googlesearch_python) (4.13.3)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from googlesearch_python) (2.32.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.9->googlesearch_python) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4>=4.9->googlesearch_python) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->googlesearch_python) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->googlesearch_python) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->googlesearch_python) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->googlesearch_python) (2025.1.31)\n",
            "Downloading googlesearch_python-1.3.0-py3-none-any.whl (5.6 kB)\n",
            "Installing collected packages: googlesearch_python\n",
            "Successfully installed googlesearch_python-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import instructor\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "from atomic_agents.agents.base_agent import BaseAgent, BaseAgentConfig, BaseIOSchema\n",
        "from atomic_agents.lib.components.agent_memory import AgentMemory\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "llm = OpenAI(\n",
        "        base_url=f\"http://{host}/v1\",\n",
        "        api_key=\"ollama\",  # required, but unused\n",
        "    )\n",
        "\n",
        "client = instructor.from_openai(\n",
        "    llm,\n",
        "    mode=instructor.Mode.JSON,\n",
        ")\n"
      ],
      "metadata": {
        "id": "yHCElQFQb2XR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from atomic_agents.lib.components.system_prompt_generator import SystemPromptGenerator\n",
        "from atomic_agents.agents.base_agent import BaseAgent, BaseAgentConfig, BaseIOSchema\n",
        "from atomic_agents.lib.components.agent_memory import AgentMemory\n",
        "from pydantic import Field\n",
        "from typing import Optional, List\n",
        "import instructor\n",
        "from instructor.client import Instructor\n",
        "from tools.googlesearchtool import GoogleSearchToolOutputSchema\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\"Analyze the document and identify if the statements made by the person about [specific topic] change or remain consistent throughout the document. Provide examples of any changes or consistencies found.\"\n",
        "\"\"\"\n",
        "\n",
        "##################\n",
        "# Input Schema ###\n",
        "##################\n",
        "class DocumentStatementChangedValidatorInputSchema(BaseIOSchema):\n",
        "    \"\"\"\n",
        "    Defines a list of rules and a document.\n",
        "    \"\"\"\n",
        "    document: str = Field(...,description=\"The document to get analysed.\")\n",
        "    topic: str = Field(...,description=\"The specific topic we are analsing.\")\n",
        "\n",
        "################\n",
        "# Output SCHEMA #\n",
        "################\n",
        "class DocumentStatementChangedValidatorOutputSchema(BaseIOSchema):\n",
        "    \"\"\"\n",
        "    Schema for Output\n",
        "    \"\"\"\n",
        "    consistent: bool = Field (..., description=\"Is the statement in the document is consistent or not\")\n",
        "    changes: list[str] = Field (..., description=\"A list of changes\")\n",
        "    linenumbers: list[int] = Field (..., decription=\"line numbers where changes of statement occur \")\n",
        "\n",
        "###################\n",
        "# Build the agent #\n",
        "###################\n",
        "\n",
        "def build_document_statement_changed_validator_agent(client : Instructor, modelid: str) -> BaseAgent:\n",
        "    \"\"\"\n",
        "        builds an agent the validates if a statement has changed over time.\n",
        "\n",
        "    \"\"\"\n",
        "    return BaseAgent(\n",
        "        config=BaseAgentConfig(\n",
        "            client=client,\n",
        "            system_prompt_generator=SystemPromptGenerator(\n",
        "                background=[\n",
        "                'You are an expert in legal documents',\n",
        "                'Your task is to analyse a document'\n",
        "                ],\n",
        "                steps=[\n",
        "                    \"Add line numbers to the document.\"\n",
        "                    \"Analyze the document and identify if the statements made by the person about [specific topic] change or remain consistent throughout the document.\",\n",
        "                    \"Provide examples of any changes or consistencies found.\"\n",
        "                ],\n",
        "                output_instructions=[\n",
        "                    \"Ensure to output examples of any changes\",\n",
        "                    \"Ensure to add the linenumber where the changes occure.\"\n",
        "                ]\n",
        "            ),\n",
        "            input_schema=DocumentStatementChangedValidatorInputSchema,\n",
        "            output_schema=DocumentStatementChangedValidatorOutputSchema,\n",
        "            model=modelid,\n",
        "            temperature=0,\n",
        "        )\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "IoMJcVuvrJfG",
        "outputId": "7bf67568-e89a-4d6b-c4ed-7ecf633e2231"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"# IDENTITY and PURPOSE\\n- This assistant is a general-purpose AI designed to be helpful and friendly.\\n\\n# INTERNAL ASSISTANT STEPS\\n- Understand the user's input and provide a relevant response.\\n- Respond to the user.\\n\\n# OUTPUT INSTRUCTIONS\\n- Provide helpful and relevant information to assist the user.\\n- Be friendly and respectful in all interactions.\\n- Always answer in rhyming verse.\\n- Always respond using the proper JSON schema.\\n- Always use the available additional information and context to enhance the response.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "document=\"\"\"\n",
        "Officer Reynolds: Good afternoon, Mrs. Harper. Thank you for coming in today. I'm Officer Reynolds, and we need to ask you some questions about your husband's death.\n",
        "\n",
        "Mrs. Harper: Good afternoon, Officer. I'll do my best to help, but I still can't believe what's happened.\n",
        "\n",
        "Officer Reynolds: I understand. We're just trying to piece together the events of that evening. Can you tell us where you were on the night of the murder?\n",
        "\n",
        "Mrs. Harper: Yes, I wasn't home that evening. I had a dinner with some friends in town.\n",
        "\n",
        "Officer Reynolds: You weren’t home at all that night?\n",
        "\n",
        "Mrs. Harper: No, I came back late, and by the time I got home, it was well past midnight. I found...I found him...\n",
        "\n",
        "Officer Reynolds: Do you have anyone who can confirm your whereabouts that evening?\n",
        "\n",
        "Mrs. Harper: Yes, I can provide you with the names of the friends I was with. They can vouch for me.\n",
        "\n",
        "Officer Reynolds: That would be helpful, Mrs. Harper. Now, if you don’t mind, can you walk me through what happened when you arrived back home?\n",
        "\n",
        "Mrs. Harper: Of course... When I got back, everything seemed normal at first. Then, I...I saw him lying there...\n",
        "\n",
        "Officer Reynolds: Take your time. It's important that we get a clear picture of that night.\n",
        "\n",
        "Mrs. Harper: I understand. I was in shock. I didn't know what to do.\n",
        "\n",
        "Officer Reynolds: Mrs. Harper, our investigation has led us to believe that you were actually at home during the time of the murder. Are you sure you weren’t there?\n",
        "\n",
        "Mrs. Harper: Wait, what? No, I told you, I wasn't home.\n",
        "\n",
        "Officer Reynolds: We have evidence suggesting otherwise. This is your last chance to be honest with us. Were you at home?\n",
        "\n",
        "Mrs. Harper: (sighs) Okay, okay... I... I was home. But I swear, I was asleep when it happened. I didn't do anything to him!\n",
        "\n",
        "Officer Reynolds: Thank you for your honesty, Mrs. Harper. We appreciate your cooperation. Can you tell us more about why you initially lied?\n",
        "\n",
        "Mrs. Harper: I was scared. I didn't want to be blamed for something I didn't do. I thought if I said I wasn’t there, it would be easier. I didn’t know what else to do.\n",
        "\n",
        "Officer Reynolds: We understand that this is difficult, but telling the truth is always the best course of action. Is there anything else you can share that might help our investigation?\n",
        "\n",
        "Mrs. Harper: I...I don't know. I just want to find out who did this to him. Please, believe me, I had nothing to do with it.\n",
        "\n",
        "Officer Reynolds: We will continue our investigation, Mrs. Harper. Thank you for your time. We'll be in touch.\n",
        "\n",
        "Mrs. Harper: Thank you, Officer. I hope you find the real culprit soon.\n",
        "\n",
        "Officer Reynolds: We'll do our best, Mrs. Harper. Take care.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "_kQHZldXFFYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "        agent=build_document_statement_changed_validator_agent(llm, args.modelid)\n",
        "\n",
        "\n",
        "        with open(\"./data/changing_murder_statement.txt\", \"r\") as file:\n",
        "            document=file.read()\n",
        "\n",
        "        input=agent.input_schema(document=document, topic=\"location at time of murder\")\n",
        "        validationResult=agent.run(input)\n",
        "        print(validationResult)"
      ],
      "metadata": {
        "id": "YkaTeOcP3HHu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}