{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPCcLGyUHK25PfptRVduLez",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ebamberg/research-projects-ml/blob/main/agents_and_routing/examples_agents_for_knowledgeGraph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ittnx9TnwT_y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GCm0uJVC9jvj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0870a45-2eb2-48d7-8996-997341b741a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "KeyboardInterrupt\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install ollama langchain_community --quiet\n",
        "\n",
        "host=\"localhost:11434\"\n",
        "modelid=\"gemma3:12b\"\n",
        "\n",
        "get_ipython().system_raw(\"curl -fsSL https://ollama.com/install.sh | sh\")\n",
        "get_ipython().system_raw(\"ollama serve &\")\n",
        "get_ipython().system_raw(f\"ollama pull {modelid}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai --quiet"
      ],
      "metadata": {
        "id": "VMom2AWiyAdg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_ipython().system_raw(f\"ollama pull {modelid}\")"
      ],
      "metadata": {
        "id": "z_AAjjHozJOM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db5705f2-a80f-4c84-d70e-59b3ef51c530"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "KeyboardInterrupt\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/ebamberg/research-projects-ml/refs/heads/main/data/text/synthetic_history_of_rock.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pL_FpdW9_L_k",
        "outputId": "d2d7b79d-7f62-483d-ed3c-bb74ad7630de"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-16 15:10:38--  https://raw.githubusercontent.com/ebamberg/research-projects-ml/refs/heads/main/data/text/synthetic_history_of_rock.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3245 (3.2K) [text/plain]\n",
            "Saving to: ‘synthetic_history_of_rock.txt.1’\n",
            "\n",
            "\r          synthetic   0%[                    ]       0  --.-KB/s               \rsynthetic_history_o 100%[===================>]   3.17K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-09-16 15:10:38 (16.6 MB/s) - ‘synthetic_history_of_rock.txt.1’ saved [3245/3245]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "\n",
        "llm = OpenAI(\n",
        "        base_url=f\"http://{host}/v1\",\n",
        "        api_key=\"ollama\",  # required, but unused\n",
        "    )\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yHCElQFQb2XR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def call(system_prompt: str, message: str, model: str = modelid ) -> str:\n",
        "  completion = llm.chat.completions.create(\n",
        "      model=modelid,\n",
        "      messages=[\n",
        "          {\"role\": \"system\", \"content\": system_prompt},\n",
        "          {\n",
        "              \"role\": \"user\",\n",
        "              \"content\": message,\n",
        "          },\n",
        "      ],\n",
        "  )\n",
        "\n",
        "  return completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "YkaTeOcP3HHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_kg_agent(content : str):\n",
        "  \"\"\"\n",
        "\n",
        "You are a helpful assistant specializing in English language tasked with extracting knowledge‑graph‑ready triplets from input sentences.\n",
        "\n",
        "Your job is to identify triplets of entity–relation–entity suitable for high‑quality Knowledge Graph construction.\n",
        "\n",
        "Output format:\n",
        "\n",
        "Return only a JSON array of objects, with no extra characters, explanations, or surrounding text.\n",
        "\n",
        "Each object must follow this exact schema (attributes are empty strings if absent):\n",
        "\n",
        "[{“head_entity”:{“entity”:<string>, “attribute”:<string>},”relation”:{“relation”:<string>, “attribute”:<string>},”tail_entity”:{“entity”:<string>, “attribute”:<string>}}]\n",
        "\n",
        "Core extraction rules:\n",
        "\n",
        "Relations: use lowercase lemma (root) form for the predicate; normalize inflected forms by lemmatization (e.g., “celebrated” → “celebrate”).\n",
        "\n",
        "Coreference: resolve pronouns and nominal references across sentences and replace them with the canonical entity mention (e.g., “He” → “Bilbo Baggins”).\n",
        "\n",
        "De‑duplication: avoid duplicate triples after normalization; keep a single instance of identical head–relation–tail.\n",
        "\n",
        "Entity cleaning: strip determiners and punctuation, preserve multi‑word names, and use a cleaned, canonical surface form where resolvable.\n",
        "\n",
        "Adjectives and modifiers: attach descriptive adjectives, ordinals, numerals, dates, and similar qualifiers as the attribute of the nearest relevant entity (e.g., “111th” on “birthday”).\n",
        "\n",
        "Prepositions and normalized relations: map common prepositional or nominal patterns to canonical snake_case relation names when appropriate (e.g., give_to, located_in, part_of, born_in, work_at).\n",
        "\n",
        "Voice normalization: for passive constructions, recover the logical subject as head and object as tail (e.g., “The ring was given to Frodo by Bilbo” → head=Bilbo, relation=give_to, tail=Frodo).\n",
        "\n",
        "Coordination: split conjuncts into multiple triples when they denote separate facts (e.g., “Bilbo and Frodo traveled to Rivendell” → two triples, one per subject).\n",
        "\n",
        "Negation: if a predicate is explicitly negated (e.g., “not”, “never”), keep the relation in lemma form and set relation.attribute to “negated”.\n",
        "\n",
        "Uncertainty and conditionals: for explicit modality/conditionality (e.g., “may”, “might”, “if”), keep the lemmatized relation and set relation.attribute to a short qualifier such as “modal:may” or “conditional”.\n",
        "\n",
        "Document level relations: allow cross‑sentence relations when clearly expressed via coreference or discourse, but do not infer unstated facts.\n",
        "\n",
        "Do not invent attributes: include only attributes explicitly present or safely normalized from the text; otherwise use an empty string.\n",
        "\n",
        "Best‑practice reminders:\n",
        "\n",
        "Prefer verb‑centric predicates; convert nominalizations to their verbal lemmas when this better captures the relation (e.g., “celebration” → “celebrate”).\n",
        "\n",
        "Keep entities and relations concise and unambiguous; avoid overlapping or synonymous duplicates (e.g., do not emit both give and give_to for the same fact).\n",
        "\n",
        "Use English throughout; process text in cleaned form before extraction.\n",
        "\n",
        "Examples:\n",
        "\n",
        "Input: “Bilbo Baggins was celebrating his 111th birthday.”\n",
        "\n",
        "Output:\n",
        "\n",
        "[{“head_entity”:{“entity”:”Bilbo Baggins”,”attribute”:””},”relation”:{“relation”:”celebrate”,”attribute”:””},”tail_entity”:{“entity”:”birthday”,”attribute”:”111th”}}]\n",
        "\n",
        "Input: “Bilbo was celebrating his birthday. He gave the ring to Frodo.”\n",
        "\n",
        "Output:\n",
        "\n",
        "[{“head_entity”:{“entity”:”Bilbo Baggins”,”attribute”:””},”relation”:{“relation”:”celebrate”,”attribute”:””},”tail_entity”:{“entity”:”birthday”,”attribute”:””}}, {“head_entity”:{“entity”:”Bilbo Baggins”,”attribute”:””},”relation”:{“relation”:”give_to”,”attribute”:””},”tail_entity”:{“entity”:”Frodo”,”attribute”:””}}]\n",
        "\n",
        "Input: “Bilbo was celebrating his birthday. Frodo celebrated the party.”\n",
        "\n",
        "Output:\n",
        "\n",
        "[{“head_entity”:{“entity”:”Bilbo”,”attribute”:””},”relation”:{“relation”:”celebrate”,”attribute”:””},”tail_entity”:{“entity”:”birthday”,”attribute”:””}}, {“head_entity”:{“entity”:”Frodo”,”attribute”:””},”relation”:{“relation”:”celebrate”,”attribute”:””},”tail_entity”:{“entity”:”party”,”attribute”:””}}]\n",
        "\n",
        "Input: “The ring was given to Frodo by Bilbo.”\n",
        "\n",
        "Output:\n",
        "\n",
        "[{“head_entity”:{“entity”:”Bilbo”,”attribute”:””},”relation”:{“relation”:”give_to”,”attribute”:””},”tail_entity”:{“entity”:”Frodo”,”attribute”:””}}]\n",
        "\n",
        "Input: “Bilbo did not attend the party.”\n",
        "\n",
        "Output:\n",
        "\n",
        "[{“head_entity”:{“entity”:”Bilbo”,”attribute”:””},”relation”:{“relation”:”attend”,”attribute”:”negated”},”tail_entity”:{“entity”:”party”,”attribute”:””}}]\n",
        "\n",
        "Return only the JSON array as specified, exactly matching the schema, with no extra characters.\n",
        "\n",
        "  \"\"\"\n",
        "  return call (build_kg_agent.__doc__, content )"
      ],
      "metadata": {
        "id": "ODbK4Rp63VTn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}