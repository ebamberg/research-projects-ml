{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN5HNK5NqEbbIY+paMdLg20",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ebamberg/research-projects-ml/blob/main/agents_and_routing/examples_react_agent_from_the_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "Install required libraries and start a LLM using OLLAMA in the background"
      ],
      "metadata": {
        "id": "mZF1aggbfNO8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "6rH-VlVWfG8-",
        "outputId": "c5232c45-623e-42cf-a85d-340d7fef5fc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m1.9/2.5 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/50.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install ollama langchain_community --quiet\n",
        "\n",
        "modelid=\"gemma3:12b\"\n",
        "\n",
        "get_ipython().system_raw(\"curl -fsSL https://ollama.com/install.sh | sh\")\n",
        "get_ipython().system_raw(\"ollama serve &\")\n",
        "get_ipython().system_raw(f\"ollama pull {modelid}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "get_ipython().system_raw(f\"ollama pull {modelid}\")"
      ],
      "metadata": {
        "id": "TMJTDjHLp-Qz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ollama-python\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "su_YpBu1MBqv",
        "outputId": "ce7f3f39-30bd-4453-d8f8-37334d04aeb7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ollama-python\n",
            "  Downloading ollama_python-0.1.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting httpx<0.27.0,>=0.26.0 (from ollama-python)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from ollama-python) (2.10.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from ollama-python) (2.32.3)\n",
            "Collecting responses<0.25.0,>=0.24.1 (from ollama-python)\n",
            "  Downloading responses-0.24.1-py3-none-any.whl.metadata (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.6/46.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.27.0,>=0.26.0->ollama-python) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<0.27.0,>=0.26.0->ollama-python) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.27.0,>=0.26.0->ollama-python) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.27.0,>=0.26.0->ollama-python) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx<0.27.0,>=0.26.0->ollama-python) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.27.0,>=0.26.0->ollama-python) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.3->ollama-python) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.3->ollama-python) (2.27.2)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.3->ollama-python) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->ollama-python) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.31.0->ollama-python) (2.3.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from responses<0.25.0,>=0.24.1->ollama-python) (6.0.2)\n",
            "Downloading ollama_python-0.1.2-py3-none-any.whl (16 kB)\n",
            "Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading responses-0.24.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: responses, httpx, ollama-python\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ollama 0.4.7 requires httpx<0.29,>=0.27, but you have httpx 0.26.0 which is incompatible.\n",
            "google-genai 1.4.0 requires httpx<1.0.0dev,>=0.28.1, but you have httpx 0.26.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed httpx-0.26.0 ollama-python-0.1.2 responses-0.24.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import rich\n",
        "import logging\n",
        "from rich.logging import RichHandler\n",
        "from rich import print\n",
        "from ollama import chat\n",
        "from ollama import ChatResponse\n",
        "from ollama import Client\n",
        "import re\n",
        "\n",
        "# model=\"llama3.2\"\n",
        "model=\"gemma3:12b\"\n",
        "host=\"http://localhost:11434\"\n",
        "\n",
        "FORMAT = \"%(message)s\"\n",
        "logging.basicConfig(\n",
        "    level=logging.INFO, format=FORMAT, datefmt=\"[%X]\", handlers=[RichHandler()]\n",
        ")\n",
        "\n",
        "log = logging.getLogger(\"simpleagent\")\n",
        "log.setLevel(logging.DEBUG)\n",
        "\n",
        "system_prompt = \"\"\"\n",
        "Think step by step. You run in a loop of THOUGHT, ACTION, PAUSE, OBSERVATION.\n",
        "At the end of the loop you output an ANSWER\n",
        "Use THOUGHT to describe your thoughts about the question you have been asked.\n",
        "Use ACTION to run one of the actions available to you - then return PAUSE.\n",
        "OBSERVATION will be the result of running those actions.\n",
        "\n",
        "Your available actions are:\n",
        "### ACTIONS\n",
        "\n",
        "\n",
        "Example session:\n",
        "\n",
        "Question: What is the mass of Earth times 2?\n",
        "THOUGHT: I need to find the mass of Earth\n",
        "ACTION: get_planet_mass: Earth\n",
        "PAUSE\n",
        "\n",
        "You will be called again with this:\n",
        "\n",
        "OBSERVATION: 5.972e24\n",
        "\n",
        "THOUGHT: I need to multiply this by 2\n",
        "ACTION: calculate: 5.972e24 * 2\n",
        "PAUSE\n",
        "\n",
        "You will be called again with this:\n",
        "\n",
        "OBSERVATION: 1,1944×10e25\n",
        "\n",
        "If you have the answer, output it as the ANSWER.\n",
        "\n",
        "ANSWER: The mass of Earth times 2 is 1,1944×10e25.\n",
        "\n",
        "Now it's your turn:\n",
        "\n",
        "\"\"\".strip()\n",
        "\n",
        "def calculate(operation:str) -> float:\n",
        "    \"\"\"\n",
        "    e.g. calculate: 4 * 7 / 3\n",
        "    Runs a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\n",
        "    \"\"\"\n",
        "    log.info(f\"calculate: {operation}\")\n",
        "    return eval(operation)\n",
        "\n",
        "def get_planet_mass(planet:str)->float:\n",
        "    \"\"\"\n",
        "    e.g. get_planet_mass: Earth\n",
        "    returns weight of the planet in kg\n",
        "    \"\"\"\n",
        "    log.info(f\"return mass of {planet} \")\n",
        "    return 3.285e23\n",
        "\n",
        "class BaseAgent:\n",
        "    \"\"\"\n",
        "    The Base Agent class.\n",
        "    This class holds a memory of previous calls and builds the foundation for agents\n",
        "    \"\"\"\n",
        "    def __init__(self, systemprompt: str=\"\", tools=[]):\n",
        "        self.log=logging.getLogger(\"agent\")\n",
        "        self.systemprompt=systemprompt\n",
        "\n",
        "        toolprompt=\"\"\n",
        "        for tool in tools:\n",
        "            toolprompt=toolprompt+tool.__name__+\":\"+tool.__doc__+\"\\n\\n\"\n",
        "        self.systemprompt=self.systemprompt.replace(\"### ACTIONS\",\"### ACTIONS\\n\\n\"+toolprompt)\n",
        "\n",
        "        log.debug(self.systemprompt)\n",
        "        self.clear_memory()\n",
        "        self.client = Client(\n",
        "         #   host='http://192.168.0.9:11434',\n",
        "            host=host,\n",
        "            headers={'x-some-header': 'some-value'}\n",
        "        )\n",
        "\n",
        "    def __add2Memory(self, role: str, message: str=\"\"):\n",
        "        if message:\n",
        "            self.memory.append({ 'role':role, 'content': message})\n",
        "\n",
        "    def __execute(self) -> str:\n",
        "        self.log.debug(f'calling with history : {self.memory}')\n",
        "        response: ChatResponse = self.client.chat(model=model, messages=self.memory,options={'temperature':0})\n",
        "        self.log.info(response)\n",
        "        self.__add2Memory(response.message.role, response.message.content)\n",
        "        return response.message.content\n",
        "\n",
        "    def __call__(self, prompt:str=\"\"):\n",
        "        if prompt:\n",
        "            self.__add2Memory(\"user\",prompt)\n",
        "        response= self.__execute()\n",
        "        return response\n",
        "\n",
        "    def clear_memory(self):\n",
        "        self.memory=[]\n",
        "        if self.systemprompt:\n",
        "            self.__add2Memory(\"system\", self.systemprompt)\n",
        "\n",
        "class ReActAgent(BaseAgent):\n",
        "    def __init__(self, systemprompt: str=\"\", tools=[]):\n",
        "        super().__init__(systemprompt,tools)\n",
        "        self.max_iterations=10\n",
        "    def __call__(self, prompt:str=\"\"):\n",
        "        loopcount=0\n",
        "        message=prompt\n",
        "        while loopcount<self.max_iterations:\n",
        "            response=super().__call__(message)\n",
        "            if \"PAUSE\" in response and \"ACTION\" in response:\n",
        "                action = re.findall(r\"ACTION: ([a-z_]+): (.+)\", response, re.IGNORECASE)\n",
        "                tool = action[0][0]\n",
        "                arg = action[0][1]\n",
        "                result=eval(f\"{tool}('{arg}')\")\n",
        "                message=f\"OBSERVATION: {result}\"\n",
        "            if \"ANSWER\" in response:\n",
        "                break\n",
        "            loopcount+=1\n",
        "\n",
        "        return response\n",
        "\n",
        "if __name__=='__main__':\n",
        "    log.info (\"----------------\\n\\nSimple agent\\n\\n-----------------\\n\")\n",
        "    log.info(\"launching!\")\n",
        "\n",
        "    agent=ReActAgent(systemprompt=system_prompt,tools=[get_planet_mass,calculate])\n",
        "    response = agent('What is the mass of Mercury times 5?')\n",
        "    print (response)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cMSzpl-sLfXI",
        "outputId": "65adc785-4abc-4db4-9a3d-72fc5e71dd5c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:simpleagent:----------------\n",
            "\n",
            "Simple agent\n",
            "\n",
            "-----------------\n",
            "\n",
            "INFO:simpleagent:launching!\n",
            "DEBUG:simpleagent:Think step by step. You run in a loop of THOUGHT, ACTION, PAUSE, OBSERVATION.\n",
            "At the end of the loop you output an ANSWER\n",
            "Use THOUGHT to describe your thoughts about the question you have been asked.\n",
            "Use ACTION to run one of the actions available to you - then return PAUSE.\n",
            "OBSERVATION will be the result of running those actions.\n",
            "\n",
            "Your available actions are:\n",
            "### ACTIONS\n",
            "\n",
            "get_planet_mass:\n",
            "    e.g. get_planet_mass: Earth\n",
            "    returns weight of the planet in kg\n",
            "    \n",
            "\n",
            "calculate:\n",
            "    e.g. calculate: 4 * 7 / 3\n",
            "    Runs a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\n",
            "    \n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Example session:\n",
            "\n",
            "Question: What is the mass of Earth times 2?\n",
            "THOUGHT: I need to find the mass of Earth\n",
            "ACTION: get_planet_mass: Earth\n",
            "PAUSE \n",
            "\n",
            "You will be called again with this:\n",
            "\n",
            "OBSERVATION: 5.972e24\n",
            "\n",
            "THOUGHT: I need to multiply this by 2\n",
            "ACTION: calculate: 5.972e24 * 2\n",
            "PAUSE\n",
            "\n",
            "You will be called again with this: \n",
            "\n",
            "OBSERVATION: 1,1944×10e25\n",
            "\n",
            "If you have the answer, output it as the ANSWER.\n",
            "\n",
            "ANSWER: The mass of Earth times 2 is 1,1944×10e25.\n",
            "\n",
            "Now it's your turn:\n",
            "INFO:simpleagent:return mass of Mercury \n",
            "INFO:simpleagent:calculate: 3.285e+23 * 5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "THOUGHT: I have calculated the mass of Mercury times \u001b[1;36m5\u001b[0m. I can now output the answer.\n",
              "ANSWER: The mass of Mercury times \u001b[1;36m5\u001b[0m is \u001b[1;36m1.6425e+24\u001b[0m.\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">THOUGHT: I have calculated the mass of Mercury times <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>. I can now output the answer.\n",
              "ANSWER: The mass of Mercury times <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> is <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.6425e+24</span>.\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}